# MultiModality-List

A list of Multimodal studies.

### AI for Science
|  Title  |   Venue  |   Date   |   Code   |
|:--------|:--------:|:--------:|:--------:|
| [Optimal Transport for Brain-Image Alignment: Unveiling Redundancy and Synergy in Neural Information Processing](https://arxiv.org/pdf/2503.10663)  | ICCV | 2025 | [Code](https://github.com/NKUShaw/OT-Alignment4brain-to-image) | 


### Zero-shot Learning
|  Title  |   Venue  |   Date   |   Code   |
|:--------|:--------:|:--------:|:--------:|
| [MMRL: Multi-Modal Representation Learning for Vision-Language Models](https://arxiv.org/abs/2503.08497)  | CVPR | 2025 | [Code](https://github.com/yunncheng/MMRL) | 
| [MMRL++: Parameter-Efficient and Interaction-Aware Representation Learning for Vision-Language Models](https://arxiv.org/abs/2505.10088)  | Arxiv | 2025 | [Code](https://github.com/yunncheng/MMRL) | 
| [Logits DeConfusion with CLIP for Few-Shot Learning](https://openaccess.thecvf.com/content/CVPR2025/html/Li_Logits_DeConfusion_with_CLIP_for_Few-Shot_Learning_CVPR_2025_paper.html)  | CVPR | 2025 | [Code]([https://github.com/yunncheng/MMRL](https://github.com/LiShuo1001/LDC)) | 
